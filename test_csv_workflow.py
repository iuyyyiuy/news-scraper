#!/usr/bin/env python3
"""
Test complete CSV export workflow
"""

import os
import sys
import csv
import io
from datetime import date, timedelta
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Add the project root to Python path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from scraper.core.csv_exporter import CSVExportService, CSVExportConfig

def test_complete_workflow():
    """Test the complete CSV export workflow"""
    print("üß™ Testing Complete CSV Export Workflow")
    print("=" * 60)
    
    try:
        service = CSVExportService()
        
        # Test 1: Basic export
        print("1Ô∏è‚É£ Testing basic export...")
        config = CSVExportConfig(max_records=5, include_content=True)
        result = service.export_articles(config)
        
        if result['success']:
            print(f"‚úÖ Basic export: {result['articles_count']} articles")
            print(f"üìÅ File: {os.path.basename(result['file_path'])}")
            
            # Verify file content
            with open(result['file_path'], 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
                print(f"üìÑ Lines in file: {len(lines)}")
                print(f"üìã Header: {lines[0]}")
        else:
            print(f"‚ùå Basic export failed: {result['message']}")
            return False
        
        # Test 2: Filtered export
        print("\n2Ô∏è‚É£ Testing filtered export...")
        config = CSVExportConfig(
            start_date=date.today() - timedelta(days=7),
            end_date=date.today(),
            sources=['BlockBeats'],
            keywords=['ÊîªÂáª', 'ÂÆâÂÖ®'],
            max_records=10,
            include_content=False
        )
        result = service.export_articles(config)
        
        if result['success']:
            print(f"‚úÖ Filtered export: {result['articles_count']} articles")
            print(f"üìä Filters: {result['filters_applied']}")
        else:
            print(f"‚ö†Ô∏è  Filtered export: {result['message']} (may be no matching articles)")
        
        # Test 3: Large export simulation
        print("\n3Ô∏è‚É£ Testing large export simulation...")
        config = CSVExportConfig(max_records=100, include_content=True)
        result = service.export_articles(config)
        
        if result['success']:
            print(f"‚úÖ Large export: {result['articles_count']} articles")
            print(f"‚è±Ô∏è  Duration: {result['duration_seconds']:.2f} seconds")
            
            # Performance check
            if result['duration_seconds'] < 30:
                print(f"‚úÖ Performance: Export completed in reasonable time")
            else:
                print(f"‚ö†Ô∏è  Performance: Export took longer than expected")
        else:
            print(f"‚ùå Large export failed: {result['message']}")
        
        # Test 4: CSV format validation
        print("\n4Ô∏è‚É£ Testing CSV format validation...")
        if result['success'] and result['file_path']:
            try:
                with open(result['file_path'], 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    rows = list(reader)
                    
                print(f"‚úÖ CSV parsing: {len(rows)} rows parsed successfully")
                
                if rows:
                    sample_row = rows[0]
                    required_columns = ['date', 'title', 'source', 'keywords', 'url']
                    missing_columns = [col for col in required_columns if col not in sample_row]
                    
                    if not missing_columns:
                        print(f"‚úÖ CSV structure: All required columns present")
                    else:
                        print(f"‚ùå CSV structure: Missing columns: {missing_columns}")
                        return False
                    
                    # Check for Chinese characters
                    if any('‰∏≠' in str(value) or 'Êîª' in str(value) for value in sample_row.values()):
                        print(f"‚úÖ Encoding: Chinese characters preserved")
                    else:
                        print(f"‚ö†Ô∏è  Encoding: No Chinese characters found in sample")
                
            except Exception as e:
                print(f"‚ùå CSV validation error: {str(e)}")
                return False
        
        # Test 5: File cleanup
        print("\n5Ô∏è‚É£ Testing file cleanup...")
        export_dir = service.export_dir
        files_before = len([f for f in os.listdir(export_dir) if f.endswith('.csv')])
        
        # Create a test file with old timestamp
        import time
        test_file = os.path.join(export_dir, 'test_old_file.csv')
        with open(test_file, 'w') as f:
            f.write('test')
        
        # Modify timestamp to make it "old"
        old_time = time.time() - (2 * 24 * 60 * 60)  # 2 days ago
        os.utime(test_file, (old_time, old_time))
        
        # Run cleanup
        service.cleanup_old_exports(days=1)
        
        files_after = len([f for f in os.listdir(export_dir) if f.endswith('.csv')])
        
        if not os.path.exists(test_file):
            print(f"‚úÖ Cleanup: Old files removed successfully")
        else:
            print(f"‚ùå Cleanup: Old files not removed")
            return False
        
        print(f"\nüéâ All workflow tests completed successfully!")
        return True
        
    except Exception as e:
        print(f"‚ùå Workflow test error: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def test_performance_benchmark():
    """Test performance with realistic data volumes"""
    print("\nüöÄ Performance Benchmark Test")
    print("=" * 60)
    
    try:
        service = CSVExportService()
        
        # Test different record counts
        test_sizes = [10, 50, 100, 500]
        
        for size in test_sizes:
            print(f"\nüìä Testing {size} records...")
            
            config = CSVExportConfig(max_records=size, include_content=True)
            result = service.export_articles(config)
            
            if result['success']:
                duration = result['duration_seconds']
                records_per_second = result['articles_count'] / duration if duration > 0 else 0
                
                print(f"‚úÖ {result['articles_count']} articles in {duration:.2f}s")
                print(f"üìà Performance: {records_per_second:.1f} records/second")
                
                # Performance thresholds
                if records_per_second > 10:
                    print(f"üöÄ Excellent performance")
                elif records_per_second > 5:
                    print(f"‚úÖ Good performance")
                else:
                    print(f"‚ö†Ô∏è  Performance could be improved")
            else:
                print(f"‚ùå Failed to export {size} records: {result['message']}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Performance test error: {str(e)}")
        return False

if __name__ == "__main__":
    print("üß™ CSV Export Complete Workflow Test")
    print("=" * 60)
    
    # Run workflow test
    workflow_success = test_complete_workflow()
    
    # Run performance test
    performance_success = test_performance_benchmark()
    
    print("\n" + "=" * 60)
    print("üìä Final Results:")
    print(f"   Workflow Test: {'‚úÖ PASSED' if workflow_success else '‚ùå FAILED'}")
    print(f"   Performance Test: {'‚úÖ PASSED' if performance_success else '‚ùå FAILED'}")
    
    if workflow_success and performance_success:
        print("üéâ All tests PASSED! CSV export is ready for production.")
    else:
        print("‚ö†Ô∏è  Some tests failed. Please review the issues above.")
    
    print("=" * 60)